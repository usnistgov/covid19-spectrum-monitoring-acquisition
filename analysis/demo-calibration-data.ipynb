{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### please work with a copy of this (or revert before git commit) to avoid git commit conflicts!\n",
    "this is a workspace for exploring the data produced during noise calibration.\n",
    "\n",
    "the analysis requires a few parameters:\n",
    "- `path`: path to a data file output from the power sweep acquisition flowgraph\n",
    "- `holdoff`: \"transient window\" duration to ignore at the start of each frequency step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dkuester noise calibration.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6eb098fa8300>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m spectrum, metadata = read.swept_average(\n\u001b[0;32m     13\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"data/{os.environ['USERNAME']} noise calibration.dat\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mholdoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.110\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\src\\covid19-spectrum-monitoring-fresh\\read.py\u001b[0m in \u001b[0;36mswept_average\u001b[1;34m(path, holdoff, dwell_settle)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mswept_average\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholdoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdwell_settle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mversion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dkuester noise calibration.dat'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import sys\n",
    "sys.path.insert(1,'..')\n",
    "import os\n",
    "import pandas as pd\n",
    "import read\n",
    "import yaml\n",
    "\n",
    "def dB(lin_power):\n",
    "    return 10*np.log10(lin_power)\n",
    "\n",
    "spectrum, metadata = read.swept_average(\n",
    "    path = f\"data/{os.environ['USERNAME']} noise calibration.dat\",\n",
    "    holdoff = 0.110,\n",
    ")\n",
    "globals().update(metadata)\n",
    "\n",
    "by_frequency = spectrum.copy()\n",
    "by_frequency.index = by_frequency.index.droplevel('Time')\n",
    "\n",
    "# look at only the last sweep\n",
    "center_frequencies = metadata.pop('center_frequencies')\n",
    "start_timestamp = metadata.pop('start_timestamp')\n",
    "by_frequency = by_frequency.iloc[-len(center_frequencies):]\n",
    "\n",
    "for f_MHz, noise_average in by_frequency.mean(axis=1).to_dict().items():\n",
    "    metadata[f_MHz*1e6]['noise_average'] = noise_average\n",
    "\n",
    "# backtest the calibration\n",
    "noise_average = by_frequency.mean(axis=1)\n",
    "corr_abs_diff = by_frequency.copy()\n",
    "corr_abs_diff.values[:] = np.abs(corr_abs_diff.values[:]-noise_average.values[:,np.newaxis])\n",
    "\n",
    "corr_trunc_diff = by_frequency.copy()\n",
    "corr_trunc_diff.values[:] -= noise_average.values[:,np.newaxis]\n",
    "corr_trunc_diff.values[:] *= (corr_trunc_diff.values[:] > 0) + 1e-20\n",
    "\n",
    "corr_mag_diff = by_frequency.copy()\n",
    "corr_mag_diff.values[:] = (np.sqrt(corr_mag_diff.values[:]) - np.sqrt(noise_average.values[:,np.newaxis]))**2\n",
    "\n",
    "dB(by_frequency.mean(axis=1)).plot(lw=0, marker='.', label='mean($P$)')\n",
    "dB(corr_abs_diff.mean(axis=1)).plot(lw=0, marker='.', label='mean(abs($P$ - mean($P$)))')\n",
    "dB(corr_trunc_diff.mean(axis=1)).plot(lw=0, marker='.', label='mean($P$: $P$ > mean($P$))')\n",
    "dB(corr_mag_diff.mean(axis=1)).plot(lw=0, marker='.', label='mean[($P^{1/2}$-mean($P$)$^{1/2}$)$^2$]')\n",
    "\n",
    "legend()\n",
    "ylabel('Power average over dwell window (dB A.U.)')\n",
    "title('Comparison of correction methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the analysis requires a few parameters:\n",
    "- `path`: path to a data file output from the power sweep acquisition flowgraph\n",
    "- `aperture_time`: the integration time for each sample of each dwell_time\n",
    "- `dwell_time`: the time acquisition spends at each frequency step\n",
    "- `dwell_settle`: the minimum number of `aperture_time` samples that must elapse before data can be valid\n",
    "- `dwell_throwaway`: number of (potentially transient) initial samples to ignore after the dwell produces valid (non-NaN) samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's useful to check that the acquisition center frequency has changed, and to verify that there are no obvious detector transients in the acquired samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dwell_slices(spectrum, fc, name, count=1):\n",
    "    fig,ax = subplots(1,1,sharey=True,sharex=True, figsize=(12,4))\n",
    "    global spectrum_slice\n",
    "    spectrum_slice = 10*log10(spectrum.reset_index().query(f'Frequency == {fc}').set_index('Time').drop('Frequency', axis=1))\n",
    "    spectrum_slice.columns = spectrum_slice.columns.astype(float)*aperture_time*1e3\n",
    "    spectrum_slice.T.iloc[:,::spectrum_slice.shape[0]//count].plot(ax=ax,lw=1)\n",
    "    xlabel('Dwell time elapsed (ms)')\n",
    "    ylabel('Average power in 1 ms (dB A.U.)')\n",
    "    title(name)\n",
    "    return fig\n",
    "\n",
    "plot_dwell_slices(spectrum, 611, '611 MHz')\n",
    "plot_dwell_slices(spectrum, 704, '704 MHz LTE Band 5 UL')\n",
    "plot_dwell_slices(spectrum, 2695, '2695 MHz Radioastronomy')\n",
    "plot_dwell_slices(spectrum, 2412, '2.4 GHz 802.11 Channel 1 UL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to explore the time p dataset, we can look at statistics of each dwell window over time. as a simple example to start, here are trends in min, max, and mean for each frequency under study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency_stats(by_sweep, fcs, name):\n",
    "    fig,axs = subplots(1,len(fcs),sharey=True,sharex=True, figsize=(12,4))\n",
    "    \n",
    "    if not hasattr(axs, '__len__'):\n",
    "        axs = [axs]\n",
    "\n",
    "    for fc, ax in zip(fcs, axs):\n",
    "        y2 = by_sweep.loc[:,('Min',fc)]\n",
    "        y1 = by_sweep.loc[:,('Max',fc)]\n",
    "        ax.fill_between(x=by_sweep.index,\n",
    "                        y1=y1,\n",
    "                        y2=y2,\n",
    "                        where=y1>y2,\n",
    "                        facecolor='green', alpha=0.2, interpolate=True)\n",
    "        by_sweep.loc[:,('Mean',fc)].plot(ax=ax,color='green')\n",
    "        ax.set_title(f'{fc} MHz')\n",
    "        if ax is axs[0]:\n",
    "            ax.set_ylabel('Average power in 1 ms (dB A.U.)')\n",
    "        if ax is axs[len(axs)//2]:\n",
    "            ax.set_xlabel('Time elapsed (s)')\n",
    "        else:\n",
    "            ax.set_xlabel('')\n",
    "        if ax is axs[-1]:\n",
    "            ax.legend(['Mean','Extrema'], title=f'In {dwell_time:0.1f}s', loc='best')\n",
    "\n",
    "    fig.suptitle(name)\n",
    "    savefig(f\"{path[:path.rfind('.')]} {name}.pdf\")\n",
    "    return fig\n",
    "\n",
    "stats = pd.DataFrame(dict(Min=spectrum.min(axis=1),\n",
    "                          Max=spectrum.max(axis=1),\n",
    "                          Mean=spectrum.mean(axis=1)))\n",
    "by_sweep = (10*log10(stats)).reset_index().set_index('Time').pivot(columns='Frequency')\n",
    "\n",
    "plot_frequency_stats(by_sweep, [704,711,782,829,844], 'LTE Uplink Bands')\n",
    "plot_frequency_stats(by_sweep, [734,741,752,874,889], 'LTE Downlink Bands')\n",
    "plot_frequency_stats(by_sweep, [2695,4995], 'Quiet bands')\n",
    "plot_frequency_stats(by_sweep, [2412,  2422,  2432], 'ISM Band (lower)')\n",
    "plot_frequency_stats(by_sweep, [2442,  2452, 2462], 'ISM Band(upper)')\n",
    "plot_frequency_stats(by_sweep, [5170,5190,5210,5230], 'U-NII1 Band (lower)')\n",
    "plot_frequency_stats(by_sweep, [5240,5775,5795], 'U-NII1 Band (upper)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml.dump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml.dump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(r'swept_power_to_disk.yaml','rb') as f:\n",
    "    d = yaml.load(f,Loader=yaml.Loader)\n",
    "    \n",
    "center_frequencies = d.pop('center_frequencies')\n",
    "for f in center_frequencies:\n",
    "    d[float(f)] = dict(power_correction=10**(-28./10), subtract=0)\n",
    "for k,v in dict(d).items():\n",
    "    if isinstance(k,str):\n",
    "        d[k] = float(v)\n",
    "\n",
    "with open(r'swept_power_to_disk-new.yaml','wb') as f:\n",
    "    yaml.dump(d,f,encoding='utf-8')\n",
    "    \n",
    "with open(r'swept_power_to_disk-new.yaml','rb') as f:\n",
    "    d2 = yaml.load(f,Loader=yaml.SafeLoader)    \n",
    "    \n",
    "d2['center_frequencies'] = [k for k in d2.keys() if isinstance(k,float)]\n",
    "d2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
